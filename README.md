# AlphaRAG 

**Production RAG for Financial Intelligence**

A high-performance Retrieval-Augmented Generation (RAG) system designed for financial document analysis. Built with production-grade optimizations including semantic caching, hybrid search, and sub-200ms P95 latency.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

---

##Features

- **High-Performance Retrieval**: Sub-200ms P95 latency with semantic caching and query optimization
- **Hybrid Search**: Combines dense vector search with sparse BM25 for superior recall
- **Smart Chunking**: Semantic document segmentation preserving financial context
- **Citation Tracking**: Exact source attribution with page/paragraph references
- **Cost Optimization**: 60% cost reduction through intelligent caching and prompt compression
- **Production-Ready**: Comprehensive error handling, monitoring, and Docker deployment

---

## Architecture

```
┌─────────────┐
│   Frontend  │
│  (Streamlit)│
└──────┬──────┘
       │
┌──────▼──────────────────────────────────────┐
│         FastAPI Backend                      │
│  ┌────────────┐  ┌──────────────┐          │
│  │   Cache    │  │   Rate       │          │
│  │   Layer    │  │   Limiter    │          │
│  └────────────┘  └──────────────┘          │
└──────┬───────────────────────────────────────┘
       │
┌──────▼──────────────────────────────────────┐
│         RAG Pipeline                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐ │
│  │  Query   │→ │Retrieval │→ │Generation│ │
│  │Optimizer │  │  Engine  │  │  (LLM)   │ │
│  └──────────┘  └──────────┘  └──────────┘ │
└──────┬───────────────────────────────────────┘
       │
┌──────▼──────────────────────────────────────┐
│         Data Layer                           │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐ │
│  │  Vector  │  │  Redis   │  │ Document │ │
│  │    DB    │  │  Cache   │  │  Store   │ │
│  └──────────┘  └──────────┘  └──────────┘ │
└──────────────────────────────────────────────┘
```

See [docs/architecture.md](docs/architecture.md) for detailed system design.

---

## Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose
- OpenAI API key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/alpharag.git
cd alpharag
```

2. **Set up environment**
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

3. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your API keys
```

4. **Start services with Docker**
```bash
docker-compose up -d
```

5. **Run the application**
```bash
# Start backend
python src/main.py

# In another terminal, start frontend
streamlit run frontend/app.py
```

Visit `http://localhost:8501` to access the application.

---

##Performance Benchmarks

| Metric | Without Optimization | With Optimization | Improvement |
|--------|---------------------|-------------------|-------------|
| **P50 Latency** | 850ms | 165ms | 5.1x faster |
| **P95 Latency** | 1,200ms | 195ms | 6.2x faster |
| **P99 Latency** | 1,800ms | 280ms | 6.4x faster |
| **Cache Hit Rate** | N/A | 42% | N/A |
| **Cost per 1K queries** | $12.50 | $4.80 | 62% reduction |
| **Throughput** | 45 QPS | 180 QPS | 4x increase |

See [benchmarks/](benchmarks/) for detailed performance analysis.

---

## Project Structure

```
alpharag/
├── src/                      # Source code
│   ├── ingestion/           # Document processing pipeline
│   ├── retrieval/           # RAG & search components
│   ├── optimization/        # Caching & performance
│   ├── evaluation/          # Metrics & testing
│   └── utils/               # Shared utilities
├── frontend/                # Streamlit UI
├── data/                    # Sample documents & datasets
├── tests/                   # Unit & integration tests
├── benchmarks/              # Performance benchmarks
├── docs/                    # Documentation
├── scripts/                 # Utility scripts
├── docker/                  # Docker configurations
└── config/                  # Configuration files
```

See individual README files in each directory for detailed documentation.

---

## Configuration

Key configuration options in `config/config.yaml`:

```yaml
# Model settings
model:
  embedding_model: "all-MiniLM-L6-v2"
  llm_model: "gpt-4-turbo-preview"
  temperature: 0.1

# Retrieval settings
retrieval:
  top_k: 5
  chunk_size: 512
  chunk_overlap: 50
  hybrid_alpha: 0.7  # Weight for dense vs sparse

# Performance
cache:
  enabled: true
  similarity_threshold: 0.95
  ttl: 3600
  
optimization:
  batch_size: 32
  use_reranking: true
```

---

## Usage Examples

### Basic Query
```python
from src.retrieval.rag_pipeline import RAGPipeline

pipeline = RAGPipeline()
result = pipeline.query(
    "What are the main risk factors in Tesla's 2024 10-K?"
)

print(result.answer)
print(f"Sources: {result.sources}")
print(f"Confidence: {result.confidence}")
```

### Batch Processing
```python
queries = [
    "Compare AAPL and MSFT revenue growth in Q4 2024",
    "What did the Fed announce about interest rates?",
    "Summarize NVDA's AI strategy"
]

results = pipeline.batch_query(queries, batch_size=16)
```

### Custom Retrieval
```python
from src.retrieval.hybrid_search import HybridSearch

searcher = HybridSearch()
docs = searcher.search(
    query="AI investment trends",
    top_k=10,
    filters={"company": "NVDA", "year": 2024}
)
```

See [docs/usage.md](docs/usage.md) for comprehensive examples.

---

## Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test suite
pytest tests/test_retrieval.py -v

# Run benchmarks
python benchmarks/run_benchmarks.py
```

---

## Evaluation

The system includes comprehensive evaluation metrics:

- **Retrieval Quality**: Precision@K, Recall@K, MRR, NDCG
- **Answer Quality**: Faithfulness, answer relevance, context relevance
- **Performance**: Latency (P50/P95/P99), throughput, cache hit rate
- **Cost**: Token usage, API costs per query

Run evaluation:
```bash
python src/evaluation/run_eval.py --eval-set data/eval/financial_qa.json
```

---

## Docker Deployment

```bash
# Build images
docker-compose build

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

Services:
- **Backend**: `localhost:8000`
- **Frontend**: `localhost:8501`
- **Redis**: `localhost:6379`
- **Vector DB**: `localhost:6333`

---

## Roadmap

- [x] Core RAG pipeline
- [x] Hybrid search implementation
- [x] Semantic caching
- [x] Performance benchmarks
- [ ] Multi-modal support (charts, tables)
- [ ] Fine-tuned reranker model
- [ ] Streaming responses
- [ ] Multi-tenant support
- [ ] Advanced analytics dashboard

---

## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## Acknowledgments

- Built with [LangChain](https://github.com/langchain-ai/langchain) and [LlamaIndex](https://github.com/run-llama/llama_index)
- Powered by [OpenAI](https://openai.com) and [Sentence Transformers](https://www.sbert.net/)
- Inspired by production ML systems at leading financial institutions

---

## Contact

**Brian Won** - [injongwbrian@gmail.com](mailto:injongwbrian@gmail.com)

Project Link: [https://github.com/yourusername/alpharag](https://github.com/yourusername/alpharag)

Portfolio: [brianwon.dev](https://brianwon.dev)

---

## Project Stats

- **Test Coverage**: 85%
- **Documentation**: private APIs
- **Performance Tests**: 25+ scenarios
- **Sample Documents**: 35+ financial filings
